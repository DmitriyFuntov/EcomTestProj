# Общая информация
ETL скрипт, написанный на java с использованием Apache Spark и работающий с хранилищем данных minio.
Скрипт создает бакет и заполняет его случайными данными или заранее заготовленными в коде данными сохраняя данные в формате parquet в соответствующих директориях input/store, order и user . После чего подтягивает данные из хранилища, обрабатывает и выгружает результат(список городов с топ 3 магазинов по продажам для каждого города) в parquet файл в директорию output/result.
 
# Структура
## Класс DataTemplate
Описывает структуру сущностей с которыми ведется работа и используется для работы с ними.
## Класс DataGenerator 
Используется только для заполнения хранилища тестовыми данными, если хранилище уже имеет нужные данные, его методы вызывать не следует.
Имеет 2 метода:
- generateRandom принимает требуемое количество заказов, магазинов и клиентов и создает объекты со случайными комбинациями свойств из заранее заготовленного набора значений.
- generateHandMade заполняет хранилище заранее заданным набором данных

## Класс DataBaseOperator
Реализует бизнес логику и используется для всех операций с хранилищем.
- конструктор принимает параметры базы данных и создает спарк сессию. 
- метод sendRequest читает данные, выполняет описанный ранее запрос и выводит результат в хранилище данных.
- метод generateData и его перегрузка вызывают один из методов класса DataGenerator, в зависимости от переданных параметров
## Класс Main 
Является точкой входа в проект, получает из переменных среды данные хранилища и передает их объекту DataBaseOperator.

# Инструкция по запуску
1. В папке testproj выполнить сначала `docker-compose build`, затем `docker-compose up`
2. Дождаться выполнения скрипта, перейти по ссылке http://localhost:9001 и авторизоваться (значения логина и пароля по умолчанию default-user и default-password соответсвенно и могут быть изменины при добавлении .env файла по образку .envExample)

# Инструкция по загрузке дополнительных данных
1. Загрузить с помощью Web-интерфейса minio файлы в соответствующие репозитории
2. Остановить compose stack 
3. Закомментировать или удалить вызов метода generateData в Main(иначе скрипт перепишет файлы)
4. Повторить шаги из инструкции по запуску
5. Далее при замене файла, просто перезапускать контейнер my-spark-app
